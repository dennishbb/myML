{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MMM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AOS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ABT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ABBV: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ACN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ADBE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AES: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AFL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for A: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for APD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ABNB: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AKAM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ALB: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ARE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ALGN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ALLE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for LNT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for ALL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for GOOG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for MO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error fetching data for AMCR: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_stock_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Fetch and store all stock data\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mfetch_and_store_all_stocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Get top 10 stocks by volatility from the stored data\u001b[39;00m\n\u001b[1;32m     69\u001b[0m top_10_stocks \u001b[38;5;241m=\u001b[39m get_top_10_volatility_stocks(db_url, table_name)\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mfetch_and_store_all_stocks\u001b[0;34m(db_url, table_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m sp500_tickers:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Fetch the last two days of data to ensure we have yesterday's data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         stock_data \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Ensure data is valid and has at least two rows\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stock_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stock_data\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stock_data) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;66;03m# Explicitly check if the data is a Series or DataFrame and access values safely\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/qiskit_env/lib64/python3.11/site-packages/yfinance/utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/projects/qiskit_env/lib64/python3.11/site-packages/yfinance/multi.py:157\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[0m\n\u001b[1;32m    150\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[1;32m    151\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[1;32m    152\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[1;32m    153\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[1;32m    154\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[1;32m    155\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[0;32m--> 157\u001b[0m         _time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def fetch_and_store_all_stocks(db_url, table_name):\n",
    "    # Fetch tickers from an S&P 500 static list or replace this with a CSV/API call\n",
    "    sp500_tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]['Symbol'].tolist()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for ticker in sp500_tickers:\n",
    "        try:\n",
    "            # Fetch the last two days of data to ensure we have yesterday's data\n",
    "            stock_data = yf.download(ticker, period=\"2d\", progress=False)\n",
    "            \n",
    "            # Ensure data is valid and has at least two rows\n",
    "            if stock_data is not None and not stock_data.empty and len(stock_data) >= 2:\n",
    "                # Explicitly check if the data is a Series or DataFrame and access values safely\n",
    "                yesterday = stock_data.iloc[-2]\n",
    "                high = yesterday.get('High', None)\n",
    "                low = yesterday.get('Low', None)\n",
    "                close = yesterday.get('Close', None)\n",
    "\n",
    "                # Ensure valid data before appending\n",
    "                if pd.notnull(high) and pd.notnull(low) and pd.notnull(close):\n",
    "                    swing = ((high - low) / close) * 100\n",
    "                    data.append({\n",
    "                        'Ticker': ticker,\n",
    "                        'High': high,\n",
    "                        'Low': low,\n",
    "                        'Close': close,\n",
    "                        '% Swing': swing\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"Not enough data for ticker: {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # Create a DataFrame for all data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Store all data in PostgreSQL\n",
    "    try:\n",
    "        engine = create_engine(db_url)\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        print(f\"All stock data stored successfully in {table_name} table.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing data to PostgreSQL: {e}\")\n",
    "\n",
    "def get_top_10_volatility_stocks(db_url, table_name):\n",
    "    # Connect to PostgreSQL and retrieve all data\n",
    "    try:\n",
    "        engine = create_engine(db_url)\n",
    "        query = f\"SELECT * FROM {table_name} ORDER BY \\\"% Swing\\\" DESC LIMIT 10\"\n",
    "        top_10_df = pd.read_sql(query, engine)\n",
    "        return top_10_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data from PostgreSQL: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Database connection URL (update with your credentials)\n",
    "db_url = \"postgresql://user:password@192.168.0.34:5432/rag_db\"\n",
    "table_name = \"all_stock_data\"\n",
    "\n",
    "# Fetch and store all stock data\n",
    "fetch_and_store_all_stocks(db_url, table_name)\n",
    "\n",
    "# Get top 10 stocks by volatility from the stored data\n",
    "top_10_stocks = get_top_10_volatility_stocks(db_url, table_name)\n",
    "\n",
    "# Display the result\n",
    "print(top_10_stocks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
